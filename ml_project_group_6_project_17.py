# -*- coding: utf-8 -*-
"""ML Project - Group 6 Project 17.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1kBijStnkRa8G2-up9BEHRNweWs1VC4od

## Project Report on "Developing a Predictive Model to Enhance Diabetes Diagnosis in Healthcare".
### *Course : Machine Learning (CS 403/603)*

### Step by step process to detect any person is with diabetes or not:
01. Importing all the required python libraries and dataset.
02. Showing dataset values (to check what kind of values are there), shape of full dataset, and showing first/last five data samples from full dataset.
03. Showing dataset attributes/columns/features.
04. Showing attributes/columns/features basic info (like Null/Not-null, integer/float etc.).
05. Showing any Null values are present or not in the dataset. Cheking for all the attributes.
06. Showing full description of all attributes/columns/features (Optional).
07. Getting value counts for the target attribute variables i.e. how many classes are present in the target attribute.
08. Visualize distributions of features/attributes and correlation analysis between the features/attributes (Optional).
09. Differentiating the target data from overall dataset and creating two dataset (one dataset for all features and another for target class).
10. Splitting the dataset into training (80%) and testing (20%) sets (percentage is not fixed, we can change it).
11. Standardizing the features (Scaling in between 0 and 1) or add polynomial features with reduced degree.
12. Training through the different machine learning model.
13. Making predictions on the test set.
14. Evaluating the model (accuracy, precision and recall etc.).
15. Plotting the confusion matrix and evaluation matrices.
16. Checking the important features (Optional).

### ML Project (Diabetes Disease Detection) : Programming Section
"""

### Importing all the required python libraries.
import numpy as np
import pandas as pd
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import accuracy_score, confusion_matrix
from sklearn.metrics import classification_report, precision_score, recall_score

import matplotlib.pyplot as plt
import seaborn as sns

### Importing the Dataset.
raw_dataset = pd.read_csv(r'/content/diabetes_new.csv')

### Showing Dataset values (to check what kind of values are there).
raw_dataset

### Showing first five data samples from full dataset.
raw_dataset.head()

### Showing last five data samples from full dataset.
raw_dataset.tail()

### Shape of full dataset.
raw_dataset.shape

### Showing dataset attributes/columns/features.
print(raw_dataset.columns)

### Showing attributes/columns/features basic info (like Null/Not-null, integer/float etc.).
raw_dataset.info()

### Showing any Null values are present or not in the dataset. Cheking for all the attributes.
raw_dataset.isnull().sum()

### Showing full description of all attributes/columns/features.
raw_dataset.describe()

### Getting value counts for the target attribute variables i.e. how many classes are present in the target attribute.
diabetes_counts = raw_dataset['Outcome'].value_counts()
print(diabetes_counts)
print("0 -> Non-Diabetic")
print("1 -> Diabetic")

### Visualize distributions of features/attributes.
sns.pairplot(raw_dataset, hue='Outcome')
plt.show()

### Correlation analysis between the features/attributes.
plt.figure(figsize=(10, 8))
correlation_matrix = raw_dataset.corr()
sns.heatmap(correlation_matrix, annot=True, fmt=".2f", cmap='coolwarm', square=True)
plt.title("Correlation Matrix")
plt.show()

### Differentiating the target data from overall dataset and creating two dataset (One dataset for all features and another for target class).
X = raw_dataset.drop(columns='Outcome', axis=1)
Y = raw_dataset['Outcome']
print("Training Data:=> ")
print(X.head())
print("Diabetes Data:=> ")
print(Y.head())

### Splitting the dataset into training (80%) and testing (20%) sets (Percentage is not fixed, we can change it).
X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42, stratify=Y)

### Standardizing the features (Scaling in between 0 and 1).
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

print("Shape of Overall Feature Data:=> ",X.shape)
print("Shape of Feature Training Data:=> ",X_train.shape)
print("Shape of Feature Testing Data:=> ",X_test.shape)
print("Shape of Overall Target Data:=> ",Y.shape)
print("Shape of Target Training Data:=> ",Y_train.shape)
print("Shape of Target Testing Data:=> ",Y_test.shape)

### Training through the Logistic Regression model.
from sklearn.linear_model import LogisticRegression

### Initializing the Logistic Regression model.
model = LogisticRegression(random_state=42)

### Trainning the model.
model.fit(X_train_scaled, Y_train)

### Making predictions on the test set.
Y_pred = model.predict(X_test_scaled)

### Evaluating the model.
accuracy_lr = accuracy_score(Y_test, Y_pred)
conf_matrix_lr = confusion_matrix(Y_test, Y_pred)
precision_report_lr = precision_score(Y_test, Y_pred)
recall_report_lr = recall_score(Y_test, Y_pred)

### Printing the evaluation results.
print(f"Model Accuracy (using Logistic Regression):=> {accuracy_lr:.2f}")
print(f"Precision Score (using Logistic Regression): {precision_report_lr:.2f}")
print(f"Recall Score (using Logistic Regression): {recall_report_lr:.2f}")
print(" ")

### Plotting the confusion matrix.
plt.figure(figsize=(8, 6))
sns.heatmap(conf_matrix_lr, annot=True, fmt='d', cmap='Blues')
plt.title('Confusion Matrix')
plt.xlabel('Predicted Label')
plt.ylabel('True Label')
plt.show()

### Checking the important features.
feature_importance = model.coef_[0]
feature_names = X.columns

### Creating a DataFrame to display feature importance.
importance_df = pd.DataFrame({
    'Feature': feature_names,
    'Importance': feature_importance
})

### Sort by absolute value of importance.
importance_df['Absolute Importance'] = importance_df['Importance'].abs()
importance_df = importance_df.sort_values(by='Absolute Importance', ascending=False)

### Sort by absolute value of importance.
print("Feature Importance (using Logistic Regression):=> ")        ### Display feature importance
print(importance_df[['Feature', 'Importance']])

### Training through the Random Forest Classifier
from sklearn.ensemble import RandomForestClassifier

### Initializing the Logistic Regression model.
model = RandomForestClassifier(n_estimators=100, random_state=42)

### Trainning the model.
model.fit(X_train_scaled, Y_train)

### Making predictions on the test set.
Y_pred = model.predict(X_test_scaled)

### Evaluating the model.
accuracy_rf = accuracy_score(Y_test, Y_pred)
conf_matrix_rf = confusion_matrix(Y_test, Y_pred)
precision_report_rf = precision_score(Y_test, Y_pred)
recall_report_rf = recall_score(Y_test, Y_pred)

### Printing the evaluation results.
print(f"Model Accuracy (using Random Forest Classifier):=> {accuracy_rf:.2f}")
print(f"Precision Score (using Random Forest Classifier): {precision_report_rf:.2f}")
print(f"Recall Score (using Random Forest Classifier): {recall_report_rf:.2f}")
print(" ")

### Plotting the confusion matrix.
plt.figure(figsize=(8, 6))
sns.heatmap(conf_matrix_rf, annot=True, fmt='d', cmap='Blues')
plt.title('Confusion Matrix')
plt.xlabel('Predicted Label')
plt.ylabel('True Label')
plt.show()

### Checking Feature Importance.
importances = model.feature_importances_
feature_names = X.columns
indices = np.argsort(importances)[::-1]

# Plotting Feature Importances.
plt.figure(figsize=(10, 6))
plt.title("Feature Importances")
plt.bar(range(X.shape[1]), importances[indices], align='center')
plt.xticks(range(X.shape[1]), feature_names[indices], rotation=45)
plt.xlim([-1, X.shape[1]])
plt.show()

### Creating a DataFrame to display feature importance.
importance_df = pd.DataFrame({
    'Feature': feature_names,
    'Importance': importances
})

### Sort by absolute value of importance.
print("Feature Importance (using Random Forest Classifier):=> ")        ### Display feature importance
print(importance_df[['Feature', 'Importance']])

### Train through the Support Vector Machine.
from sklearn.svm import SVC

### Initializing the Logistic Regression model.
model = SVC(random_state=42)

### Trainning the model.
model.fit(X_train_scaled, Y_train)

### Making predictions on the test set.
Y_pred = model.predict(X_test_scaled)

### Evaluating the model.
accuracy_svm = accuracy_score(Y_test, Y_pred)
conf_matrix_svm = confusion_matrix(Y_test, Y_pred)
precision_report_svm = precision_score(Y_test, Y_pred)
recall_report_svm = recall_score(Y_test, Y_pred)

### Printing the evaluation results.
print(f"Model Accuracy (using Support Vector Machine):=> {accuracy_svm:.2f}")
print(f"Precision Score (using Support Vector Machine): {precision_report_svm:.2f}")
print(f"Recall Score (using Support Vector Machine): {recall_report_svm:.2f}")
print(" ")

### Plotting the confusion matrix.
plt.figure(figsize=(8, 6))
sns.heatmap(conf_matrix_svm, annot=True, fmt='d', cmap='Blues')
plt.title('Confusion Matrix')
plt.xlabel('Predicted Label')
plt.ylabel('True Label')
plt.show()

### Train through the Gradient Boosting Classifier.
from sklearn.ensemble import GradientBoostingClassifier

### Initializing the Logistic Regression model.
model = GradientBoostingClassifier(random_state=42)

### Trainning the model.
model.fit(X_train_scaled, Y_train)

### Making predictions on the test set.
Y_pred = model.predict(X_test_scaled)

### Evaluating the model.
accuracy_gb = accuracy_score(Y_test, Y_pred)
conf_matrix_gb = confusion_matrix(Y_test, Y_pred)
precision_report_gb = precision_score(Y_test, Y_pred)
recall_report_gb = recall_score(Y_test, Y_pred)

### Printing the evaluation results.
print(f"Model Accuracy (using Gradient Boosting Classifier):=> {accuracy_gb:.2f}")
print(f"Precision Score (using Gradient Boosting Classifier): {precision_report_gb:.2f}")
print(f"Recall Score (using Gradient Boosting Classifier): {recall_report_gb:.2f}")
print(" ")

### Plotting the confusion matrix.
plt.figure(figsize=(8, 6))
sns.heatmap(conf_matrix_gb, annot=True, fmt='d', cmap='Blues')
plt.title('Confusion Matrix')
plt.xlabel('Predicted Label')
plt.ylabel('True Label')
plt.show()

### Train through the XGB Classifier.
import xgboost as xgb

### Initializing the Logistic Regression model.
model = xgb.XGBClassifier(random_state=42)

### Trainning the model.
model.fit(X_train_scaled, Y_train)

### Making predictions on the test set.
Y_pred = model.predict(X_test_scaled)

### Evaluating the model.
accuracy_xgb = accuracy_score(Y_test, Y_pred)
conf_matrix_xgb = confusion_matrix(Y_test, Y_pred)
precision_report_xgb = precision_score(Y_test, Y_pred)
recall_report_xgb = recall_score(Y_test, Y_pred)

### Printing the evaluation results.
print(f"Model Accuracy (using XGB Classifier):=> {accuracy_xgb:.2f}")
print(f"Precision Score (using XGB Classifier): {precision_report_xgb:.2f}")
print(f"Recall Score (using XGB Classifier): {recall_report_xgb:.2f}")
print(" ")

### Plotting the confusion matrix.
plt.figure(figsize=(8, 6))
sns.heatmap(conf_matrix_xgb, annot=True, fmt='d', cmap='Blues')
plt.title('Confusion Matrix')
plt.xlabel('Predicted Label')
plt.ylabel('True Label')
plt.show()

# Summary of different model with respect to performance/accuracy
print("Model Performance Summary:")
print(f"Logistic Regression Accuracy:=> {accuracy_lr:.2f}")
print(f"Random Forest Accuracy:=> {accuracy_rf:.2f}")
print(f"Support Vector Machine Accuracy:=> {accuracy_svm:.2f}")
print(f"Gradient Boosting Accuracy:=> {accuracy_gb:.2f}")
print(f"XGB (Extreme Gradient Boosting):=> {accuracy_xgb:.2f}")



"""## **Only Ensemble Model : Voting Classifier**"""

import pandas as pd
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.preprocessing import StandardScaler, PolynomialFeatures
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, VotingClassifier
from sklearn.svm import SVC
from sklearn.metrics import classification_report, accuracy_score, confusion_matrix, roc_curve, auc
import xgboost as xgb
import matplotlib.pyplot as plt
import seaborn as sns

raw_dataset = pd.read_csv(r'/content/diabetes_new.csv')

X = raw_dataset .drop(columns=['Outcome'])
y = raw_dataset ['Outcome']

poly = PolynomialFeatures(degree=2, interaction_only=False, include_bias=False)   ### Adding polynomial features.
X_poly = poly.fit_transform(X)      ### print(X_poly)

X_train, X_test, y_train, y_test = train_test_split(X_poly, y, test_size=0.2, random_state=42, stratify=y)

scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

lr_model = LogisticRegression(random_state=42)
rf_model = RandomForestClassifier(random_state=42)
svm_model = SVC(random_state=42, probability=True)
gb_model = GradientBoostingClassifier(random_state=42)
xgb_model = xgb.XGBClassifier(random_state=42)

### Voting Classifier (Ensemble of models).
### ‘soft’, predicts the class label based on the argmax of the sums of the predicted probabilities.
ensemble_model = VotingClassifier(estimators=[
    ('lr', lr_model), ('rf', rf_model), ('svm', svm_model), ('gb', gb_model), ('xgb', xgb_model)],
    voting='soft'
)

### Training models.
ensemble_model.fit(X_train_scaled, y_train)

### Making predictions on the test set.
y_pred_ensemble = ensemble_model.predict(X_test_scaled)

### Evaluating models.
accuracy_ensemble = accuracy_score(y_test, y_pred_ensemble)

### Confusion Matrices.
conf_matrix_ensemble = confusion_matrix(y_test, y_pred_ensemble)

### Classification Reports.
class_report_ensemble = classification_report(y_test, y_pred_ensemble)

### ROC Curve for the best model (let's assume ensemble for now).
y_prob_ensemble = ensemble_model.predict_proba(X_test_scaled)[:, 1]
fpr, tpr, _ = roc_curve(y_test, y_prob_ensemble)
roc_auc = auc(fpr, tpr)

### Plotting the ROC curve.
plt.figure(figsize=(8, 6))
plt.plot(fpr, tpr, label=f'Ensemble Model (AUC = {roc_auc:.2f})', color='darkorange')
plt.plot([0, 1], [0, 1], linestyle='--', color='navy')
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('ROC Curve')
plt.legend(loc='lower right')
plt.show()

### Plotting the confusion matrix for the ensemble model.
plt.figure(figsize=(8, 6))
sns.heatmap(conf_matrix_ensemble, annot=True, fmt='d', cmap='Blues')
plt.title('Ensemble Model Confusion Matrix')
plt.xlabel('Predicted Label')
plt.ylabel('True Label')
plt.show()

### Summary of model performances.
print("Model Performance Summary:")
print(f"Ensemble Model Accuracy: {accuracy_ensemble:.2f}")



# Summary of different model with respect to performance/accuracy
print("Model Performance Summary:")
print(f"Logistic Regression Accuracy:=> {accuracy_lr:.2f}")
print(f"Random Forest Accuracy:=> {accuracy_rf:.2f}")
print(f"Support Vector Machine Accuracy:=> {accuracy_svm:.2f}")
print(f"Gradient Boosting Accuracy:=> {accuracy_gb:.2f}")
print(f"XGB (Extreme Gradient Boosting):=> {accuracy_xgb:.2f}")
print(f"Ensemble Model Accuracy (Voting Classifier):=> {accuracy_ensemble:.2f}")





"""## **Ensemble Model : Stacking Model**"""

import pandas as pd
from sklearn.model_selection import train_test_split, RandomizedSearchCV
from sklearn.preprocessing import StandardScaler, PolynomialFeatures
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, StackingClassifier
from sklearn.svm import SVC
from sklearn.metrics import roc_curve, auc, accuracy_score, confusion_matrix, precision_recall_curve, f1_score
import xgboost as xgb
import matplotlib.pyplot as plt
import seaborn as sns
from imblearn.over_sampling import SMOTE
from scipy.stats import uniform, randint

# Load the dataset
data = pd.read_csv(r'/content/diabetes_new.csv')

# Separate features and target variable
X = data.drop(columns='Outcome')
y = data['Outcome']
# X = raw_dataset.drop(columns='Outcome', axis=1)       # Y = raw_dataset['Outcome']

# Add polynomial features with reduced degree
poly = PolynomialFeatures(degree=2, interaction_only=False, include_bias=False)
X_poly = poly.fit_transform(X)

# Handle class imbalance using SMOTE
smote = SMOTE(random_state=42)
X_poly, y = smote.fit_resample(X_poly, y)

# Split the dataset into training (80%) and testing (20%) sets
X_train, X_test, y_train, y_test = train_test_split(X_poly, y, test_size=0.2, random_state=42, stratify=y)

# Standardize the features
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# Initialize models
rf_model = RandomForestClassifier(random_state=42)
svm_model = SVC(random_state=42, probability=True)
gb_model = GradientBoostingClassifier(random_state=42)
xgb_model = xgb.XGBClassifier(random_state=42)

# Hyperparameter distributions for RandomizedSearchCV
param_dist_rf = {
    'n_estimators': randint(50, 150),
    'max_depth': randint(5, 15),
    'min_samples_split': randint(2, 10)
}
param_dist_svm = {
    'C': uniform(0.1, 10),
    'gamma': ['scale', 'auto'],
    'kernel': ['rbf', 'linear']
}
param_dist_gb = {
    'n_estimators': randint(50, 150),
    'learning_rate': uniform(0.01, 0.1),
    'max_depth': randint(3, 7)
}
param_dist_xgb = {
    'n_estimators': randint(50, 150),
    'learning_rate': uniform(0.01, 0.1),
    'max_depth': randint(3, 7)
}

# Perform RandomizedSearch for the best parameters with n_iter=10 to speed up
rf_model = RandomizedSearchCV(rf_model, param_distributions=param_dist_rf, n_iter=10, cv=3, scoring='accuracy', n_jobs=-1, random_state=42).fit(X_train_scaled, y_train).best_estimator_
svm_model = RandomizedSearchCV(svm_model, param_distributions=param_dist_svm, n_iter=10, cv=3, scoring='accuracy', n_jobs=-1, random_state=42).fit(X_train_scaled, y_train).best_estimator_
gb_model = RandomizedSearchCV(gb_model, param_distributions=param_dist_gb, n_iter=10, cv=3, scoring='accuracy', n_jobs=-1, random_state=42).fit(X_train_scaled, y_train).best_estimator_
xgb_model = RandomizedSearchCV(xgb_model, param_distributions=param_dist_xgb, n_iter=10, cv=3, scoring='accuracy', n_jobs=-1, random_state=42).fit(X_train_scaled, y_train).best_estimator_

# Train individual models and store their predictions
models = {
    'Random Forest': rf_model,
    'Support Vector Machine (SVM)': svm_model,
    'Gradient Boosting': gb_model,
    'XGBoost (XGB)': xgb_model
}

model_predictions = {}
model_probs = {}
model_accuracies = {}
model_roc_aucs = {}

for name, model in models.items():
    model.fit(X_train_scaled, y_train)
    y_pred = model.predict(X_test_scaled)
    y_prob = model.predict_proba(X_test_scaled)[:, 1]

    model_predictions[name] = y_pred
    model_probs[name] = y_prob

    accuracy = accuracy_score(y_test, y_pred)
    fpr, tpr, _ = roc_curve(y_test, y_prob)
    roc_auc = auc(fpr, tpr)

    model_accuracies[name] = accuracy
    model_roc_aucs[name] = (fpr, tpr, roc_auc)

    # print(f"{name} Model Accuracy: {accuracy:.2f}")
    # print(f"{name} Model AUC: {roc_auc:.2f}")

    # Plot confusion matrix
    conf_matrix = confusion_matrix(y_test, y_pred)
    # plt.figure(figsize=(8, 6))
    sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues')
    # plt.title(f'{name} Model Confusion Matrix')
    # plt.xlabel('Predicted Label')
    # plt.ylabel('True Label')
    # plt.show()

# Stacking Classifier (Ensemble of models)
stacking_model = StackingClassifier(
    estimators=[
        ('lr', LogisticRegression(random_state=42)),
        ('rf', rf_model),
        ('svm', svm_model),
        ('gb', gb_model),
        ('xgb', xgb_model)
    ],
    final_estimator=LogisticRegression(),
    cv=3,
    n_jobs=-1
)

# Train the stacking model
stacking_model.fit(X_train_scaled, y_train)

# Stacking model predictions
y_pred_stacking = stacking_model.predict(X_test_scaled)
y_prob_stacking = stacking_model.predict_proba(X_test_scaled)[:, 1]

# Calculate accuracy and ROC-AUC for stacking model
accuracy_stacking = accuracy_score(y_test, y_pred_stacking)
fpr_stacking, tpr_stacking, _ = roc_curve(y_test, y_prob_stacking)
roc_auc_stacking = auc(fpr_stacking, tpr_stacking)

print(f"Stacking Model Accuracy: {accuracy_stacking:.2f}")
print(f"Stacking Model AUC: {roc_auc_stacking:.2f}")

# Plot confusion matrix for stacking model
conf_matrix_stacking = confusion_matrix(y_test, y_pred_stacking)
plt.figure(figsize=(8, 6))
sns.heatmap(conf_matrix_stacking, annot=True, fmt='d', cmap='Blues')
plt.title('Stacking Model Confusion Matrix')
plt.xlabel('Predicted Label')
plt.ylabel('True Label')
plt.show()

# Plot ROC-AUC curves for all models
plt.figure(figsize=(10, 8))
for name, (fpr, tpr, roc_auc) in model_roc_aucs.items():
    plt.plot(fpr, tpr, label=f'{name} (AUC = {roc_auc:.2f})')
plt.plot(fpr_stacking, tpr_stacking, label=f'Stacking Model (AUC = {roc_auc_stacking:.2f})', color='black', linestyle='--')
plt.plot([0, 1], [0, 1], linestyle='--', color='navy')
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('ROC-AUC Curve Comparison')
plt.legend(loc='lower right')
plt.show()



# Summary of different model with respect to performance/accuracy
print("Model Performance Summary:")
print(f"Logistic Regression Accuracy:=> {accuracy_lr*100:.2f}%")
print(f"Random Forest Accuracy:=> {accuracy_rf*100:.2f}%")
print(f"Support Vector Machine Accuracy:=> {accuracy_svm*100:.2f}%")
print(f"Gradient Boosting Accuracy:=> {accuracy_gb*100:.2f}%")
print(f"XGB (Extreme Gradient Boosting):=> {accuracy_xgb*100:.2f}%")
print(f"Ensemble Model Accuracy (Voting Classifier):=> {accuracy_ensemble*100:.2f}%")
print(f"Ensemble (Stacking) Model Accuracy:=> {accuracy_stacking*100:.2f}%")











"""## **Another Diabetic Dataset**"""

import pandas as pd
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.preprocessing import StandardScaler, PolynomialFeatures
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, VotingClassifier
from sklearn.svm import SVC
from sklearn.metrics import classification_report, accuracy_score, confusion_matrix, roc_curve, auc
import xgboost as xgb
import matplotlib.pyplot as plt
import seaborn as sns

raw_dataset = pd.read_csv(r'/content/diabetes_012_health_indicators_BRFSS2015.csv')
print(raw_dataset.columns)

X = raw_dataset .drop(columns=['Diabetes_012'])
y = raw_dataset ['Diabetes_012']

